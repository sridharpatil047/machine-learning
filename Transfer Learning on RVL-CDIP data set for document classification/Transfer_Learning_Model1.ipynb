{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import datetime\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>imagesv/v/o/h/voh71d00/509132755+-2755.tif</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>imagesl/l/x/t/lxt19d00/502213303.tif</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>imagesx/x/e/d/xed05a00/2075325674.tif</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>imageso/o/j/b/ojb60d00/517511301+-1301.tif</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>imagesq/q/z/k/qzk17e00/2031320195.tif</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         path  label\n",
       "0  imagesv/v/o/h/voh71d00/509132755+-2755.tif      3\n",
       "1        imagesl/l/x/t/lxt19d00/502213303.tif      3\n",
       "2       imagesx/x/e/d/xed05a00/2075325674.tif      2\n",
       "3  imageso/o/j/b/ojb60d00/517511301+-1301.tif      3\n",
       "4       imagesq/q/z/k/qzk17e00/2031320195.tif      7"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_path = \"/home/sridharpatil047/transfer_learning/\"\n",
    "img_dir = root_path+\"data_final\"\n",
    "df = pd.read_csv(root_path+'labels_final.csv')\n",
    "\n",
    "#df = df.head(350) ## Comment this later\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48000, 2)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## converting labels to string because flow_from_dataframe requires labels to be str\n",
    "df['label'] = df.label.astype(str)\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 50\n",
    "EPOCHS =15\n",
    "IMG_SIZE = (224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 32160 validated image filenames belonging to 16 classes.\n",
      "Found 15840 validated image filenames belonging to 16 classes.\n"
     ]
    }
   ],
   "source": [
    "datagen = tf.keras.preprocessing.image.ImageDataGenerator(validation_split=0.33,\n",
    "                                                         preprocessing_function=tf.keras.applications.vgg16.preprocess_input)\n",
    "\n",
    "train_generator = datagen.flow_from_dataframe(df,directory=img_dir, x_col='path', y_col='label',subset='training', \n",
    "                                              class_mode='categorical', target_size=IMG_SIZE,\n",
    "                                              batch_size=BATCH_SIZE)\n",
    "\n",
    "valid_generator = datagen.flow_from_dataframe(df,directory=img_dir, x_col='path', y_col='label',subset='validation',\n",
    "                                              class_mode='categorical', target_size=IMG_SIZE,\n",
    "                                              batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32160, 15840)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator.n, valid_generator.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((224, 224, 3), (224, 224, 3))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator.image_shape, valid_generator.image_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "## code inspired from here: https://www.tensorflow.org/tutorials/images/transfer_learning\n",
    "model1_path = root_path+'models/model1/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "## source: https://www.tensorflow.org/tutorials/images/transfer_learning#freeze_the_convolutional_base\n",
    "IMG_SHAPE = IMG_SIZE + (3,)\n",
    "model_VGG16 = tf.keras.applications.VGG16(include_top=False, weights='imagenet', input_shape=IMG_SHAPE)\n",
    "model_VGG16.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "644/644 [==============================] - 5321s 8s/step - loss: 3.6017 - acc: 0.1340 - val_loss: 2.4150 - val_acc: 0.2413\n",
      "Epoch 2/15\n",
      "644/644 [==============================] - 5318s 8s/step - loss: 2.3280 - acc: 0.2929 - val_loss: 2.0986 - val_acc: 0.3812\n",
      "Epoch 3/15\n",
      "644/644 [==============================] - 5321s 8s/step - loss: 2.0879 - acc: 0.3704 - val_loss: 1.9347 - val_acc: 0.4155\n",
      "Epoch 4/15\n",
      "644/644 [==============================] - 5316s 8s/step - loss: 1.9201 - acc: 0.4152 - val_loss: 1.7983 - val_acc: 0.4568\n",
      "Epoch 5/15\n",
      "644/644 [==============================] - 5319s 8s/step - loss: 1.7730 - acc: 0.4606 - val_loss: 1.6172 - val_acc: 0.5028\n",
      "Epoch 6/15\n",
      "644/644 [==============================] - 5316s 8s/step - loss: 1.6084 - acc: 0.5042 - val_loss: 1.4807 - val_acc: 0.5481\n",
      "Epoch 7/15\n",
      "644/644 [==============================] - 5306s 8s/step - loss: 1.4862 - acc: 0.5389 - val_loss: 1.3910 - val_acc: 0.5805\n",
      "Epoch 8/15\n",
      "644/644 [==============================] - 5304s 8s/step - loss: 1.3893 - acc: 0.5691 - val_loss: 1.3256 - val_acc: 0.5991\n",
      "Epoch 9/15\n",
      "644/644 [==============================] - 5301s 8s/step - loss: 1.3003 - acc: 0.5983 - val_loss: 1.2864 - val_acc: 0.6126\n",
      "Epoch 10/15\n",
      "644/644 [==============================] - 5307s 8s/step - loss: 1.2399 - acc: 0.6144 - val_loss: 1.2298 - val_acc: 0.6365\n",
      "Epoch 11/15\n",
      "644/644 [==============================] - 5307s 8s/step - loss: 1.1745 - acc: 0.6311 - val_loss: 1.2045 - val_acc: 0.6444\n",
      "Epoch 12/15\n",
      "644/644 [==============================] - 5308s 8s/step - loss: 1.1293 - acc: 0.6474 - val_loss: 1.1740 - val_acc: 0.6539\n",
      "Epoch 13/15\n",
      "644/644 [==============================] - 5312s 8s/step - loss: 1.0785 - acc: 0.6623 - val_loss: 1.1529 - val_acc: 0.6604\n",
      "Epoch 14/15\n",
      "644/644 [==============================] - 5306s 8s/step - loss: 1.0387 - acc: 0.6736 - val_loss: 1.1435 - val_acc: 0.6636\n",
      "Epoch 15/15\n",
      "644/644 [==============================] - 5311s 8s/step - loss: 0.9986 - acc: 0.6861 - val_loss: 1.1135 - val_acc: 0.6739\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(model_VGG16)\n",
    "model.add(tf.keras.layers.Conv2D(128, (3,3), padding='same', activation='relu', \n",
    "                                 kernel_initializer='he_uniform'))\n",
    "model.add(tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2,2), padding='same'))\n",
    "\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(tf.keras.layers.Dense(64, activation='relu', kernel_initializer='he_uniform'))\n",
    "model.add(tf.keras.layers.Dense(32, activation='relu', kernel_initializer='he_uniform'))\n",
    "\n",
    "model.add(tf.keras.layers.Dense(16, activation='softmax'))\n",
    "\n",
    "base_learning_rate = 0.0001\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(lr=base_learning_rate),\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "              metrics=['acc'])\n",
    "\n",
    "log_dir = model1_path + datetime.datetime.now().strftime(\"%m%d%Y-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "model.fit(train_generator,\n",
    "          epochs=EPOCHS,\n",
    "          validation_data=valid_generator,\n",
    "         callbacks=[tensorboard_callback])\n",
    "model.save(model1_path+'model1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
