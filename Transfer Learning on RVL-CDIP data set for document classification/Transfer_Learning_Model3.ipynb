{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import datetime\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>imagesv/v/o/h/voh71d00/509132755+-2755.tif</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>imagesl/l/x/t/lxt19d00/502213303.tif</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>imagesx/x/e/d/xed05a00/2075325674.tif</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>imageso/o/j/b/ojb60d00/517511301+-1301.tif</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>imagesq/q/z/k/qzk17e00/2031320195.tif</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         path  label\n",
       "0  imagesv/v/o/h/voh71d00/509132755+-2755.tif      3\n",
       "1        imagesl/l/x/t/lxt19d00/502213303.tif      3\n",
       "2       imagesx/x/e/d/xed05a00/2075325674.tif      2\n",
       "3  imageso/o/j/b/ojb60d00/517511301+-1301.tif      3\n",
       "4       imagesq/q/z/k/qzk17e00/2031320195.tif      7"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_path = \"/home/sridharpatil047/transfer_learning/\"\n",
    "img_dir = root_path+\"data_final\"\n",
    "df = pd.read_csv(root_path+'labels_final.csv')\n",
    "\n",
    "#df = df.head(50) ## Comment this later\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48000, 2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## converting labels to string because flow_from_dataframe requires labels to be str\n",
    "df['label'] = df.label.astype(str)\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 50\n",
    "EPOCHS =5\n",
    "IMG_SIZE = (224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 32160 validated image filenames belonging to 16 classes.\n",
      "Found 15840 validated image filenames belonging to 16 classes.\n"
     ]
    }
   ],
   "source": [
    "datagen = tf.keras.preprocessing.image.ImageDataGenerator(validation_split=0.33,\n",
    "                                                         preprocessing_function=tf.keras.applications.vgg16.preprocess_input)\n",
    "\n",
    "train_generator = datagen.flow_from_dataframe(df,directory=img_dir, x_col='path', y_col='label',subset='training', \n",
    "                                              class_mode='categorical', target_size=IMG_SIZE,\n",
    "                                              batch_size=BATCH_SIZE)\n",
    "\n",
    "valid_generator = datagen.flow_from_dataframe(df,directory=img_dir, x_col='path', y_col='label',subset='validation',\n",
    "                                              class_mode='categorical', target_size=IMG_SIZE,\n",
    "                                              batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32160, 15840)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator.n, valid_generator.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((224, 224, 3), (224, 224, 3))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator.image_shape, valid_generator.image_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## code inspired from here: https://www.tensorflow.org/tutorials/images/transfer_learning\n",
    "model3_path = root_path+'models/model3/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.keras.engine.input_layer.InputLayer object at 0x7f4b099ec310> False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f4b099ec8d0> False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f4b0bde8d90> False\n",
      "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f4b0bdee390> False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f4bc29e3150> False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f4bc295a610> False\n",
      "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f4b099f1c90> False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f4bc29bb150> False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f4b099f6b50> False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f4b099fb4d0> False\n",
      "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f4b09987bd0> False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f4b0998bb50> False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f4b09990e90> False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f4b09994e10> True\n",
      "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f4b0999dfd0> True\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f4bb4333cd0> True\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f4b099a35d0> True\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f4b099ac090> True\n",
      "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f4b099b4e50> True\n"
     ]
    }
   ],
   "source": [
    "## source: https://www.tensorflow.org/tutorials/images/transfer_learning#freeze_the_convolutional_base\n",
    "IMG_SHAPE = IMG_SIZE + (3,)\n",
    "model_VGG16 = tf.keras.applications.VGG16(include_top=False, weights='imagenet', input_shape=IMG_SHAPE)\n",
    "\n",
    "## Making last 6 layers trainable and rest non-trainable\n",
    "for layer in model_VGG16.layers[:13]:\n",
    "    layer.trainable = False\n",
    "\n",
    "for layer in model_VGG16.layers:\n",
    "    print(layer, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "644/644 [==============================] - 7024s 11s/step - loss: 1.4948 - acc: 0.5804 - val_loss: 1.0376 - val_acc: 0.6898\n",
      "Epoch 2/5\n",
      "644/644 [==============================] - 6830s 11s/step - loss: 0.9048 - acc: 0.7384 - val_loss: 0.7961 - val_acc: 0.7626\n",
      "Epoch 3/5\n",
      "644/644 [==============================] - 6838s 11s/step - loss: 0.7208 - acc: 0.7900 - val_loss: 0.7586 - val_acc: 0.7753\n",
      "Epoch 4/5\n",
      "644/644 [==============================] - 6829s 11s/step - loss: 0.5888 - acc: 0.8289 - val_loss: 0.7032 - val_acc: 0.7942\n",
      "Epoch 5/5\n",
      "644/644 [==============================] - 6829s 11s/step - loss: 0.4803 - acc: 0.8619 - val_loss: 0.6867 - val_acc: 0.8040\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(model_VGG16)\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(1024, (7,7), padding='valid', activation='sigmoid'))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(tf.keras.layers.Conv2D(512, (1,1), padding='valid', activation='sigmoid'))\n",
    "model.add(tf.keras.layers.Dropout(0.2))\n",
    "model.add(tf.keras.layers.Conv2D(16, (1,1), padding='valid', activation='sigmoid'))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "\n",
    "base_learning_rate = 0.0001\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(lr=base_learning_rate),\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "              metrics=['acc'])\n",
    "\n",
    "log_dir = model3_path + datetime.datetime.now().strftime(\"%m%d%Y-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "model.fit(train_generator,\n",
    "          epochs=EPOCHS,\n",
    "          validation_data=valid_generator,\n",
    "         callbacks=[tensorboard_callback])\n",
    "model.save(model3_path + 'model3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
